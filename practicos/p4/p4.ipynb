{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</center><img src=\"https://www3.um.edu.uy/logoum.jpg\" width=300></center>\n",
    "<h1 align=\"center\">Introducción a la Ciencia de Datos</h1>\n",
    "<h2 align=\"center\"> <font color='gray'>Práctico 4: Regresiones y clasificación</font></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</center><img src=\"images/who.png\" width=800></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='289C4E'>Tabla de contenidos<font><a class='anchor' id='inicio'>\n",
    "- [Importe las librerías necesarias](#0)\n",
    "- [Utilize una regresión lineal para predecir](#1)\n",
    "- [Grafique la línea de mejor ajuste](#2)\n",
    "- [Evalúe el nivel de precisión de nuestra predicción](#3)\n",
    "- [Caso multivariante](#4)\n",
    "- [Regresión lineal multivariante extensión](#5)\n",
    "- [Normalización](#6)\n",
    "- [Wine dataset](#7)\n",
    "- [Hyperparameter tunning](#8)\n",
    "- [Logistic regression](#9)\n",
    "- [Decision tree classifiers](#10)\n",
    "    \n",
    "Al finalizar el práctico usted aprenderá:\n",
    "- Qué es una regresión lineal.\n",
    "- Cómo entrenar un modelo lineal.\n",
    "- Cómo generar predicciones con un modelo lineal.\n",
    "- Cómo evaluar las predicciones del modelo.\n",
    "- Extensión al caso multivariante.\n",
    "- Cómo es afectado un modelo lineal por medio de una normalización.\n",
    "- Noción de Cross-Validation, Training set, Validation set y Testing set. Parte de teórico.\n",
    "- Regresión logística para clasificación binaria.\n",
    "- Árboles de decisión para clasificación de dos o más clases.\n",
    "\n",
    "\n",
    "<font color='FF1000'> **Nota:** en este práctico no se le dará mayor relevancia a todo lo referente a la validación de modelos. Prácticamente en todo el práctico usted entrenará y evaluará en el conjunto de entrenamiento. Esto se conoce como **validación de resustitución (resubstitution validation)** y no es una práctica frecuente, pues introduce sesgos optimistas en la estimación del rendimiento o performance predictiva del modelo.<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='289C4E'>0) Importe las librerías necesarias<font> <a class='anchor' id='0'></a> [↑](#inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import linear_model, metrics, model_selection\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qué es una regresión lineal?\n",
    "\n",
    "Es un modelo que encuentra la mejora línea recta que se ajusta a nuestros datos. Estos modelos predicen con buena exactitud cuando los datos se comportan linealmente.\n",
    "\n",
    "### Ejemplo\n",
    "\n",
    "Frecuentemente, se nos presentan una serie de datos $\\mathbf{x}$ con el fin de predecir una \"respuesta\" $\\mathbf{y}$. Por ejemplo, podríamos llegar a predecir por medio de una regresión la `nota_de_examen` (variable $\\mathbf{y}$) por medio de la variable `horas_de_estudio` (nuestra variable $\\mathbf{x}$).\n",
    "\n",
    "Generemos unos datos de ejemplo y examinemos la relación existente entre $\\mathbf{x}$ e $\\mathbf{y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEICAYAAACwDehOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAasklEQVR4nO3de5RdZZ3m8e9jJUCBlwIp6FyIQVZWQECIXU2jKG0T7eCNlCDthWEiK2Ps1QxC26YhuqZp6V4jWIqXcdo2SDuhpbkIRcLYDDFEvLVNtEJhCoy1olxiKpEUYAFKNSTxN3/st3ZO4ily6nLOrqr9fNaqdc55z97n/XE09dTe797vq4jAzMwM4CVFF2BmZhOHQ8HMzHIOBTMzyzkUzMws51AwM7OcQ8HMzHJ1CwVJ/yxpp6QHK9qOkLRO0pb0eHhql6QvSvq5pE2SXlevuszMbHiq130Kks4EfgPcEBEnpbZPA09FxNWSrgAOj4jLJb0duAR4O/DHwBci4o8P1MeRRx4Zc+fOrUv9ZmZT1caNG5+IiNZq702rV6cR8T1Jc/drXgy8OT1fBXwHuDy13xBZQt0nqUXSjIjY8WJ9zJ07l66urvEs28xsypP02HDvNXpM4eihX/Tp8ajUPgv4ZcV221KbmZk10EQZaFaVtqrntSQtk9Qlqau/v7/OZZmZlUujQ+FxSTMA0uPO1L4NOKZiu9nA9mofEBErI6ItItpaW6ueEjMzs1FqdCjcCSxJz5cAayra/2u6Cul04OkDjSeYmdn4q9tAs6SbyAaVj5S0DbgSuBq4VdJSYCtwftr8LrIrj34OPAdcVK+6zMxsePW8+uj9w7y1sMq2AVxcr1rMzKaC1d19dKztZfvAIDNbmlm+aD7tC8b3mpy6hYKZmY2f1d19rOjsYXDXHgD6BgZZ0dkDMK7BMFGuPjIzsxfRsbY3D4Qhg7v20LG2d1z7cSiYmU0C2wcGR9Q+Wg4FM7NJYGZL84jaR8uhYGY2CSxfNJ/m6U37tDVPb2L5ovnj2o8Hms3MJoGhwWRffWRmZkAWDOMdAvvz6SMzM8s5FMzMLOdQMDOznEPBzMxyDgUzM8s5FMzMLOdQMDOznEPBzMxyDgUzM8sVEgqSLpX0oKSHJF2W2o6QtE7SlvR4eBG1mZmVWcNDQdJJwIeA04BTgHdKmgdcAayPiHnA+vTazMwaqIgjhROA+yLiuYjYDXwXeDewGFiVtlkFtBdQm5lZqRURCg8CZ0p6paRDgbcDxwBHR8QOgPR4VAG1mZmVWsNnSY2IzZKuAdYBvwF+AuyudX9Jy4BlAHPmzKlLjWZmZVXIQHNEXB8Rr4uIM4GngC3A45JmAKTHncPsuzIi2iKirbW1tXFFm5mVQFFXHx2VHucA5wI3AXcCS9ImS4A1RdRmZlZmRS2yc7ukVwK7gIsj4teSrgZulbQU2AqcX1BtZmalVUgoRMSbqrQ9CSwsoBwzM0t8R7OZmeUcCmZmlnMomJlZzqFgZma5oq4+MjOryeruPjrW9rJ9YJCZLc0sXzSf9gWzii5rynIomNmEtbq7jxWdPQzu2gNA38AgKzp7ABwMdeLTR2Y2YXWs7c0DYcjgrj10rO0tqKKpz6FgZhPW9oHBEbXb2DkUzGzCmtnSPKJ2GzuHgplNWMsXzad5etM+bc3Tm1i+aH5BFU19Hmg2swlraDDZVx81jkPBzCa09gWzHAIN5NNHZmaWcyiYmVnOoWBmZjmHgpmZ5YpajvOvJD0k6UFJN0k6RNKxkjZI2iLpFkkHFVGbmVmZNTwUJM0CPgK0RcRJQBPwPuAa4HMRMQ/4NbC00bWZmZVdUaePpgHNkqYBhwI7gLOA29L7q4D2gmozMyuthodCRPQBnwG2koXB08BGYCAidqfNtgG+MNnMrMGKOH10OLAYOBaYCRwGvK3KpjHM/sskdUnq6u/vr1+hZmYlVMTpo7cAj0REf0TsAjqBNwAt6XQSwGxge7WdI2JlRLRFRFtra2tjKjYzK4kiQmErcLqkQyUJWAj8FLgXeE/aZgmwpoDazMxKrYgxhQ1kA8r3Az2phpXA5cBHJf0ceCVwfaNrMzMru0ImxIuIK4Er92t+GDitgHLMzCzxHc1mZpZzKJiZWc6hYGZmOYeCmZnlvPKamU1oq7v7vBxnAzkUzGzCWt3dx4rOHgZ37QGgb2CQFZ09AA6GOvHpIzObsDrW9uaBMGRw1x461vYWVNHU51Awswlr+8DgiNpt7BwKZjZhzWxpHlG7jZ1DwcwmrOWL5tM8vWmftubpTSxfNL+giqY+DzSb2YQ1NJjsq48ax6FgZhNa+4JZDoEGOmAoSDoYOA+YW7l9RFxVv7LMzKwItRwprGHvkpnP17ccMzMrUi2hMDsizq57JWY2ofhO4nKq5eqjH0o6ue6VmNmEMXQncd/AIMHeO4lXd/cVXZrVWS2h8EZgo6ReSZsk9UjaNNoOJc2X9EDFzzOSLpN0hKR1krakx8NH24eZjY3vJC6vWk4fvW08O4yIXuBUAElNQB9wB3AFsD4irpZ0RXp9+Xj2bWa18Z3E5XXAI4WIeAw4BjgrPX+ulv1qtBD4RfrcxcCq1L4KaB+nPsxshF7RPH1E7TZ1HPCXu6Qryf5iX5GapgNfH6f+3wfclJ4fHRE7ANLjUePUh5mNkDSydps6avmL/93AOcBvASJiO/CysXYs6aD0ud8Y4X7LJHVJ6urv7x9rGWZWxcBzu0bUblNHLaHwQkQEEACSDhunvt8G3B8Rj6fXj0uakfqYAeystlNErIyItohoa21tHadSzKySJ6Irr1pC4VZJXwFaJH0IuAe4bhz6fj97Tx0B3AksSc+XkN00Z2YF8ER05XXAq48i4jOS3go8A8wH/jYi1o2lU0mHAm8FPlzRfDVZAC0FtgLnj6UPMxs9T0RXXsrODNWwofRy9p376Kl6FVWrtra26OrqKroMM7NJRdLGiGir9l4tE+J9GLgKGAR+B4hsfOHV41mkmZkVr5ab1z4GnBgRT9S7GDMzK1YtA82/ILthzczMprhajhRWkE2Kt4GKqbMj4iN1q8rMzApRSyh8Bfg20EM2pmBmZlNULaGwOyI+WvdKzMyscLWMKdybppaYkaa3PkLSEXWvzMzMGq6WI4UPpMcVFW2+JNXMbAqq5Y7mYxtRiJmZFa+WIwUknQS8BjhkqC0ibqhXUWZmVoxa7mi+EngzWSjcRTa76Q8Ah4KZ2RRTy0Dze8hWSPtVRFwEnAIcXNeqzMysELWcPhqMiN9J2p0mxduJB5nN6mZ1d59nJ7XC1BIKXZJayNZQ2Aj8BvhRXasyK6nV3X2s6OxhcNceAPoGBlnR2QPgYLCGOODpo4j4y4gYiIh/IlsDYUk6jWRm46xjbW8eCEMGd+2hY21vQRVZ2RwwFNKiNwBExKPAQ2nw2czG2faBwRG1m423WgaaF0q6K93RfBJwH/CysXQqqUXSbZJ+JmmzpNenO6XXSdqSHg8fSx9mk5HXRrai1XL66APAKrIJ8e4CLouIj42x3y8Ad0fE8WRXM20GrgDWR8Q8YH16bVYqXhvZilbL6aN5wKXA7cCjwIVpjeVRSVcwnQlcDxARL0TEALCYLHxIj+2j7cNssmpfMItPnXsys1qaETCrpZlPnXuyB5mtYWq5+uj/Av89Iu6RJOCjwI+BE0fZ56uBfuBrkk4hu6LpUuDoiNgBEBE7JB01ys83m9TaF8xyCFhhahlTOC0i7gGIzGcZ21/x04DXAV+OiAXAbxnBqaI0Y2uXpK7+/v4xlGFmZvurJRR2S/ofkq6D/HTSWE5wbgO2RcSG9Po2spB4XNKM1McMspvkfk9ErIyItohoa21tHUMZZma2v1pC4Wtky3C+Pr3eBvzDaDuMiF8Bv5Q0FCwLgZ8CdwJLUtsSYM1o+zAzs9GpZUzhuIh4r6T3A0TEYBpbGItLgBslHQQ8DFxEFlC3pvsitgLnj7EPMzMboVpC4QVJzWQL6yDpOLIjh1GLiAeAtipvLRzL55qZ2djUEgpXAncDx0i6ETgD+GA9izIzs2LUsvLaOkn3A6cDAi6NiCfqXpmZmTVcTSuvRcSTwL/VuRYzMytYLVcfmZlZSdR0pGBWFl7gxsqupiMFSW+UdFF63irp2PqWZdZ4Qwvc9A0MEuxd4GZ1d1/RpZk1TC0T4l0JXA6sSE3Tga/XsyizIniBG7PajhTeDZxDNkcREbGdMa6nYDYReYEbs9pC4YWICPbevHZYfUsyK4YXuDGrLRRulfQVoEXSh4B7gOvqW5ZZ43mBG7Pabl77jKS3As+QzY76txGxru6VmTXY0FVGvvrIykzZmaHJqa2tLbq6uoouw8xsUpG0MSKqzT83/JGCpGdJ4wjVRMTLx6E2MzObQIYNhYh4GYCkq4BfAf9CNvfRBfjqIzOzKamWgeZFEfGPEfFsRDwTEV8Gzqt3YWZm1ni1hMIeSRdIapL0EkkXAHsOuJeZmU06tYTCB4A/Bx5PP+entlGT9KikHkkPSOpKbUdIWidpS3o8fCx9mJnZyB0wFCLi0YhYHBFHRkRrRLRHxKPj0PefRsSpFSPgVwDrI2IesD69NjOzBppIU2cvBlal56uA9gJrMTMrpaJCIYBvSdooaVlqOzoidgCkx6MKqs3MrLSKWk/hjIjYLukoYJ2kn9W6YwqRZQBz5sypV31mZqVUUyhIegdwInDIUFtEXDXaTtNMq0TETkl3AKcBj0uaERE7JM0Adg6z70pgJWR3NI+2BjMz+321rKfwT8B7gUvIbl47H3jVaDuUdJikoRvjDgP+DHgQuBNYkjZbAqwZbR9mZjY6tRwpvCEiXitpU0R8UtJngc4x9Hk0cIekof7/NSLulvRjshlZlwJbycLHzMwaqJZQGFph5DlJM4EngVEvxxkRDwOnVGl/Elg42s81M7OxqyUUvimpBegA7ie7cuirda3KzMwKUUsofDoingdul/RNssHm/6xvWWZmVoRa7lP4j6EnEfF8RDxd2WZmZlPHi62n8AfALKBZ0gKyK48AXg4c2oDazMyswV7s9NEi4IPAbODaivZngY/XsSYzMyvIiy2yswpYJem8iLi9gTWZmVlBahlTWC/pWkld6eezkl5R98rMzKzhagmF68lOGf15+nkG+Fo9izIzs2LUcknqcRFRufzmJyU9UK+CzMysOLUcKQxKeuPQC0lnsPcuZzMzm0JqOVL4C+CGNI4g4Cmyq5LMzGyKOWAoRMRPgFMkvTy9fqbuVZmZWSEOGAqSDgbOA+YC09LspmNaT8HMzCamWk4frQGeBjYCz9e3HDMzK1ItoTA7Is6ueyVmZla4Wq4++qGkk+teiZmZFa6WUHgjsFFSr6RNknokbRprx5KaJHWn6biRdKykDZK2SLpF0kFj7cPMzEamltNHb6tT35cCm8lmXQW4BvhcRNyc1oVeCny5Tn3bBLO6u4+Otb1sHxhkZkszyxfNp33BrKLLMiudAx4pRMRj1X7G0qmk2cA7SCu4Kbuk6SzgtrTJKqB9LH3Y5LG6u48VnT30DQwSQN/AICs6e1jd3Vd0aWalU8vpo3r4PPA3wO/S61cCAxGxO73eRraWg5VAx9peBnft2adtcNceOtb2FlSRWXk1PBQkvRPYGREbK5urbBrD7L9saMbW/v7+utRojbV9oPqsKcO1m1n9FHGkcAZwjqRHgZvJTht9HmiRNDTGMRvYXm3niFgZEW0R0dba2tqIeq3OZrY0j6jdzOqn4aEQESsiYnZEzAXeB3w7Ii4A7gXekzZbQnbTnJXA8kXzaZ7etE9b8/Qmli+aX1BFZuVV1JhCNZcDH5X0c7IxhusLrscapH3BLD517snMamlGwKyWZj517sm++sisAIqoeup+Umhra4uurq6iyzAzm1QkbYyItmrvTaQjBTMzK5hDwczMcg4FMzPLORTMzCznUDAzs5xDwczMcg4FMzPLORTMzCznUDAzs5xDwczMcg4FMzPLORTMzCznUDAzs5xDwczMctMOvIlNZau7++hY28v2gUFmtjSzfNF8r2NgVmIOhRJb3d3His4eBnftAaBvYJAVnT0ADgazkmr46SNJh0j6kaSfSHpI0idT+7GSNkjaIukWSQc1uray6VjbmwfCkMFde+hY21tQRWZWtCLGFJ4HzoqIU4BTgbMlnQ5cA3wuIuYBvwaWFlBbqWwfGBxRu5lNfQ0Phcj8Jr2cnn4COAu4LbWvAtobXVvZzGxpHlG7mU19hVx9JKlJ0gPATmAd8AtgICJ2p022AT6pXWfLF82neXrTPm3N05tYvmh+QRWZWdEKGWiOiD3AqZJagDuAE6ptVm1fScuAZQBz5sypW41lMDSY7KuPzGxIoVcfRcSApO8ApwMtkqalo4XZwPZh9lkJrARoa2urGhxWu/YFsxwCZpYr4uqj1nSEgKRm4C3AZuBe4D1psyXAmkbXZmZWdkUcKcwAVklqIgulWyPim5J+Ctws6R+AbuD6AmozMyu1hodCRGwCFlRpfxg4rdH1mJnZXp77yMzMcg4FMzPLee6jkvOEeGZWyaFQYp4Qz8z259NHJeYJ8cxsfw6FEvOEeGa2P4dCiXlCPDPbn0OhxDwhnpntzwPNJeYJ8cxsfw6FkvOEeGZWyaePzMws51AwM7OcQ8HMzHIOBTMzyzkUzMws51AwM7NcEctxHiPpXkmbJT0k6dLUfoSkdZK2pMfDG12bmVnZFXGksBv464g4ATgduFjSa4ArgPURMQ9Yn16bmVkDNTwUImJHRNyfnj8LbAZmAYuBVWmzVUB7o2szMyu7QscUJM0lW695A3B0ROyALDiAo4qrzMysnAoLBUkvBW4HLouIZ0aw3zJJXZK6+vv761egmVkJFRIKkqaTBcKNEdGZmh+XNCO9PwPYWW3fiFgZEW0R0dba2tqYgs3MSqLhE+JJEnA9sDkirq14605gCXB1elxTrxq8LrGZWXVFzJJ6BnAh0CPpgdT2cbIwuFXSUmArcH49Ove6xGZmw2t4KETEDwAN8/bCevf/YusSOxTMrOxKd0ez1yU2Mxte6ULB6xKbmQ2vdKHgdYnNzIZXuuU4vS6xmdnwShcK4HWJzcyGU7rTR2ZmNjyHgpmZ5RwKZmaWcyiYmVnOoWBmZjlFRNE1jJqkfuCxousYoyOBJ4ouYgLx97GXv4t9+fvYa6zfxasiouo005M6FKYCSV0R0VZ0HROFv4+9/F3sy9/HXvX8Lnz6yMzMcg4FMzPLORSKt7LoAiYYfx97+bvYl7+Pver2XXhMwczMcj5SMDOznEOhIJKOkXSvpM2SHpJ0adE1FU1Sk6RuSd8supaiSWqRdJukn6X/j7y+6JqKIumv0r+RByXdJOmQomtqJEn/LGmnpAcr2o6QtE7SlvR4+Hj151Aozm7gryPiBOB04GJJrym4pqJdCmwuuogJ4gvA3RFxPHAKJf1eJM0CPgK0RcRJQBPwvmKrarj/A5y9X9sVwPqImAesT6/HhUOhIBGxIyLuT8+fJftHX9r5vCXNBt4BfLXoWoom6eXAmcD1ABHxQkQMFFtVoaYBzZKmAYcC2wuup6Ei4nvAU/s1LwZWpeergPbx6s+hMAFImgssADYUW0mhPg/8DfC7oguZAF4N9ANfS6fTvirpsKKLKkJE9AGfAbYCO4CnI+JbxVY1IRwdETsg+wMTOGq8PtihUDBJLwVuBy6LiGeKrqcIkt4J7IyIjUXXMkFMA14HfDkiFgC/ZRxPD0wm6Vz5YuBYYCZwmKT/UmxVU5tDoUCSppMFwo0R0Vl0PQU6AzhH0qPAzcBZkr5ebEmF2gZsi4ihI8fbyEKijN4CPBIR/RGxC+gE3lBwTRPB45JmAKTHneP1wQ6FgkgS2TnjzRFxbdH1FCkiVkTE7IiYSzaI+O2IKO1fgxHxK+CXkuanpoXATwssqUhbgdMlHZr+zSykpIPu+7kTWJKeLwHWjNcHl3KN5gniDOBCoEfSA6nt4xFxV4E12cRxCXCjpIOAh4GLCq6nEBGxQdJtwP1kV+x1U7I7myXdBLwZOFLSNuBK4GrgVklLyYLz/HHrz3c0m5nZEJ8+MjOznEPBzMxyDgUzM8s5FMzMLOdQMDOznEPBJh1JcytnjCySpL+T9LE6fXaLpL8cxX5vHpppVtI5kkp5N7SNjkPBSidNrDYZtAAjDoVKEXFnRFw9TvVYCTgUbLJqknRdmmf/W5KaASSdKuk+SZsk3TE0z7yk70j6n5K+C1wq6V2SNqQJ5+6RdHTa7k8kPZB+uiW9bP+OJX1CUq+ke4D5Fe3HSbpb0kZJ35d0fJV9D0vz4/84ff7i1H6ipB+lfjdJmkd2g9Jxqa2j8ggg7fMlSR9Mz89Oay/8ADi3YpsPSvpSev4qSevT56+XNGfs/zPYVONQsMlqHvC/I+JEYAA4L7XfAFweEa8Fesju/hzSEhF/EhGfBX4AnJ4mnLuZbIZWgI8BF0fEqcCbgMHKTiX9IdlUHAvIfvn+UcXbK4FLIuIP0+f8Y5W6P0E2jccfAX8KdKQZUP8C+ELqt41s/qMrgF9ExKkRsXy4LyItOnMd8K5U8x8Ms+mXgBvSd3Mj8MXhPtPKa7IcRpvt75GIGJoeZCMwV9IryH7xfze1rwK+UbHPLRXPZwO3pMnEDgIeSe3/Dlwr6UagMyK27dfvm4A7IuI5AEl3pseXkk3U9o1sih4ADq5S95+RTf43NA5xCDAH+A/gE2ldic6I2FLxOQdyPNn3sSXV8nVgWZXtXs/eo4h/AT5dawdWHj5SsMnq+Yrne6jtD5zfVjz/X8CXIuJk4MNkv5xJ59//G9AM3FftFBBQbW6YlwAD6a/6oZ8Tqmwn4LyKbeZExOaI+FfgHLIjk7WSzqqy7272/TdbuSzlaOar8Rw39nscCjZlRMTTwK8lvSk1XQh8d5jNXwH0pedDs00i6biI6ImIa4Ausr/CK30PeLek5jTe8K7U9zPAI5LOT58jSadU6XctcEma8RNJC9Ljq4GHI+KLZDNgvhZ4Fqgc03gMeI2kg9NR0cLU/jPgWEnHpdfvH+a/+YfsXcryArJTaGb7cCjYVLOE7Dz9JuBU4Kphtvs7slM93weeqGi/TNkC8T8h+6v9/1XulJZQvQV4gGwtjO9XvH0BsDTt+xDZ4jD7+3tgOrApXVb796n9vcCDacbc48nO/T8J/HuqpyMifgncCmwiGxPoTjX9J9npon9LA82PDfPf/BHgovTdXEi2JrbZPjxLqpmZ5XykYGZmOYeCmZnlHApmZpZzKJiZWc6hYGZmOYeCmZnlHApmZpZzKJiZWe7/A/2kbZFrJadqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "horas_de_estudio = np.array([1, 3, 3, 4, 5, 6, 7, 7, 8, 8, 10])\n",
    "nota_de_examen = np.array([18, 26, 31, 40, 55, 62, 71, 70, 75, 85, 97])\n",
    "plt.scatter(horas_de_estudio, nota_de_examen)\n",
    "plt.xlabel('horas de estudio')\n",
    "plt.ylabel('nota de examen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo lineal\n",
    "\n",
    "#### Hipótesis\n",
    "\n",
    "Un modelo lineal establece una \"hipótesis\" sobre la verdadera naturaleza de la función subyacente. Es decir, esta hipótesis es que se asume que los datos se comportan de manera lineal. En nuestro ejemplo, al usar un modelo lineal para predecir la nota de examen a partir de las horas de estudio estamos asumiendo que la nota de examen puede ser expresada o predicha por medio de una función lineal de las horas de estudio. \n",
    "\n",
    "Se expresa esta hipótesis en el caso univariante por medio de la función:\n",
    "\n",
    "$$h(x) = a.x + b$$\n",
    "\n",
    "En otras palabras:\n",
    "\n",
    "$$nota\\_de\\_examen(horas\\_de\\_estudio) = coeficiente * (horas\\_de\\_estudio) + constante $$\n",
    "\n",
    "Nuestro simple ejemplo es un ejemplo de **regresión univariante**, es decir la variable que queremos predecir es predicha por solo una variable o atributo. Si tenemos más de una variable para predecir la variable objetivo entonces estamos en un caso de **regresión multivariante**. En este caso la fórmula sería:\n",
    "\n",
    "$$h_\\theta(\\mathbf{X}) = \\mathbf{\\theta}^\\top \\mathbf{X} + \\mathbf{b} $$\n",
    "\n",
    "En este caso más general, lo que en la regresión univariante era el **coeficiente \"a\"** (un número) ahora en la regresión multivariante pasa a ser un **vector de coeficientes \"a\"**. Asimismo, lo que en la regresión univariante era el **vector de puntos \"x\"** (un vector con nuestra variable) ahora en la regresión multivariante pasa a ser una **matriz de puntos \"X\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Univariante\n",
    "a = 54\n",
    "b = 3\n",
    "x = [4,5,6]\n",
    "\n",
    "### Multivariante\n",
    "tita = [1,2,3]\n",
    "b = [3 ,5 ,6]\n",
    "x = [4,5,6]\n",
    "\n",
    "1*4+2*5+3*6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='289C4E'>1) Utilize una regresión lineal para predecir<font> <a class='anchor' id='1'></a> [↑](#inicio) \n",
    "    \n",
    "a) Prediga la nota de examen utilizando las horas de estudio por medio de una regresión lineal. Para eso:\n",
    "1. Defina un modelo, es decir, asígnele a una variable el modelo.\n",
    "2. Ajuste el modelo. Para eso se utiliza la función **.fit()**. Ajustar/Entrenar/Fit es la jerga utilizada en Machine Learning para referirse al hecho de aprender los parámetros del modelo.\n",
    "\n",
    "b) Conteste luego en un markdown las siguientes preguntas:\n",
    "1. Utilize el método **.coef_** para obtener el primer parámetro de la regresión. Qué es este parámetro? Cuál es su valor? Qué nos indica?\n",
    "2. Utilize el método **.intercept_** para obtener el segundo parámetro de la regresión. Qué es este parámetro? Cuál es su valor? Qué nos indica?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_modelo_lineal.fit(X)\n",
    "mi_modelo_lineal.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='289C4E'>2) Grafique la línea de mejor ajuste<font> <a class='anchor' id='2'></a> [↑](#inicio)\n",
    "    \n",
    "- Grafique la línea de mejor ajuste utilizando la función [plt.plot()](https://matplotlib.org/3.5.0/api/_as_gen/matplotlib.pyplot.plot.html#matplotlib.pyplot.plot)\n",
    "- Grafique los datos utilizando la función [plt.scatter()](https://matplotlib.org/3.5.0/api/_as_gen/matplotlib.pyplot.scatter.html#matplotlib.pyplot.scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='289C4E'>3) Evalúe el nivel de precisión de nuestra predicción<font> <a class='anchor' id='3'></a> [↑](#inicio)\n",
    "  \n",
    "Luego de generar predicciones es de nuestro interés evaluar el nivel de precisión de las mismas. Esto tiene varios fines. El primero por supuesto es evaluar qué tan bueno es nuestro modelo predictivo. Segundo, nos permite comparar modelos y ver cuál desempeña mejor. Finalmente, nos permite afinar nuestros híper-parámetros (hyperparameter tunning). \n",
    "\n",
    "Existen numerosas maneras de evaluar nuestros modelos. La evaluación siempre se mide por medio de métricas. Éstas son fórmulas matemáticas con fines específicos que intentan expresar una característica del modelo. Por ejemplo, una métrica muy utilizada es **Mean Absolute Error (MAE)**. Ésta mide la diferencia absoluta entre nuestra predicción y el valor real, en sí es una medida de precisión:\n",
    "\n",
    "$$ MAE = \\frac{\\sum_{i=1}^{n}|y - \\hat{y}|}{n} $$\n",
    "\n",
    "Otra métrica muy utilizada es **Root Mean Squared Error (RMSE)**. Al igual que MAE, es una medida de precisión, pero ésta penaliza más fuertemente los errores más grandes. En definitiva, si utilizamos ésta métrica para evaluar nuestro modelo obtendríamos modelos más robustos. Su fórmula es:\n",
    "\n",
    "$$ RMSE = \\sqrt{\\frac{\\sum_{i=1}^{n} (y - \\hat{y})^{2}}{n}} $$\n",
    "\n",
    "1. Define los vectores (listas) `y_true` (valores reales) y `y_pred` (valores predichos). Para obtener `y_pred` deberá usar el método **model.predict()**. Esta se aplica al modelo, es decir, una vez que el modelo ha sido \"entrenado\" esta es la función utilizada para generar las predicciones.\n",
    "2. Calcule el MAE utilizando la función [sklearn.metrics.mean_absolute_error()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error)\n",
    "3. Calcule el RMSE utilizando la función [sklearn.metrics.mean_squared_error()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error), deberá realizarle la raíz cuadrada al valor obtenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='289C4E'>4) Caso multivariante<font> <a class='anchor' id='3'></a> [↑](#inicio)\n",
    "\n",
    "En general, tendremos $n$ registros/filas y $p$ atributos/columnas, resultando en una matriz/tabla que tendrá $n$ filas y $p$ columnas.\n",
    "\n",
    "Volviendo al ejemplo del examen, si añadimos un nuevo atributo `horas_de_sueño` (la noche antes del examen) tendremos 2 atributos. Supongamos que tenemos 4 data points, entonces un ejemplo de nuestra matriz sería:\n",
    "\n",
    "$$\n",
    "\\left[\n",
    "  \\begin{array}{ccc}\n",
    "    y_{1} & y_{2} & y_{3} & y_{4}\\\\\n",
    "  \\end{array}\n",
    "\\right]\n",
    "=\n",
    "\\left[\n",
    "  \\begin{array}{ccc}\n",
    "    a_{11}\\\\\n",
    "    a_{21}\\\\\n",
    "  \\end{array}\n",
    "\\right]^{T}\n",
    "\\begin{bmatrix}\n",
    "    x_{11} & x_{12} & x_{13} & x_{14}\\\\\n",
    "    x_{21} & x_{22} & x_{23} & x_{24}\\\\\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\left[\n",
    "  \\begin{array}{ccc}\n",
    "    b_{1}\\\\\n",
    "  \\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "A continuación, se ha añadido una columna más llamada `horas_de_sueño`. Entrene un modelo de regresión lineal y obtenga los coeficientes. Interprete cada uno. \n",
    "\n",
    "**Nota:** puede ser de utilidad imprimir las dimensiones. Si el array no tiene las dimensiones correctas no podrá ser utilizado para entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 3, 3, 4, 5, 6, 7, 7, 8, 8, 10],\n",
    "             [2, 2.5, 3, 4, 6, 6.5, 7.2, 7.5, 8, 8.5, 10]])\n",
    "y = np.array([18, 26, 31, 40, 55, 62, 71, 70, 75, 85, 97])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='289C4E'>5) Regresión lineal multivariante extensión<font> <a class='anchor' id='5'></a> [↑](#inicio)\n",
    "\n",
    "1. Cargue el CSV **data**. \n",
    "2. Estudie las correlaciones entre las variables existentes utilizando [sns.pairplot()](https://seaborn.pydata.org/generated/seaborn.pairplot.html#seaborn.pairplot). Están bien correlacionadas?\n",
    "3. Entrene un modelo lineal (no tenga en cuenta la variable `state` para el entrenamiento) y evalúe el ajuste utilizando RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='289C4E'>6) Normalización<font> <a class='anchor' id='6'></a> [↑](#inicio)\n",
    "\n",
    "1. Normalize las columnas x1, x2, x3 usando [MinMaxScaler()](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html). Entrene un modelo lineal.\n",
    "2. Qué ha sucedido con los coeficientes de la regresión? Tiene sentido el cambio? \n",
    "3. Evalúe el ajuste utilizando RMSE. Qué conclusión puede sacar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='000000'>Training and testing<font>\n",
    "\n",
    "Hasta ahora hemos simplemente entrenado modelos con el 100% de los datos que disponemos. En la práctica esto nunca se hace, pues el objetivo de un modelo es generalizar más allá de los datos de entrenamiento. Usualmente dado un conjunto de datos se divide éste en tres datasets: **training dataset, validation dataset y testing dataset**. \n",
    "\n",
    "En este curso, no cubriremos los conceptos de **cross-validation** (validación cruzada), ya que es un tema central de Machine Learning. Sin embargo, se dará una intuición del concepto ya que es central y vital en cualquier proyecto que involucre la Ciencia de Datos.\n",
    "\n",
    "Dada una serie de datos, lo común es dividir los datos disponibles en distintos conjuntos para **entrenar** un modelo, **validar** y **testear** el mismo. Pondremos una analogía para ilustrar el concepto de validación cruzada. Suponga que usted tiene muy poco tiempo para preparar un examen y posee una serie de examenes viejos con soluciones. Entonces usted decide:\n",
    "- Estudiar el 70% de los exámenes mirando las soluciones.\n",
    "- Hacer 20% de los restantes sin mirar inicialmente las soluciones. Luego, mirará las soluciones para refinarse, estudiando qué errores ha cometido con más frecuencia y usted estará mejor preparado.\n",
    "- Hacer el 10% de los restantes para verdaderamente evaluar sus conocimientos. Con este 10% usted obtendrá una idea real de cuál será su performance el día del exámen.\n",
    "\n",
    "El 70% de los exámenes corresponderían a su **training dataset**, es decir, usted se entrenó estudiando ese 70%. Los modelos de Machine Learning **ajustan sus parámetros internos** con este dataset. Luego, el 20% de los exámenes es su **validation dataset**, es decir, refinará sus conocimientos con este dataset. En machine learning se usa este dataset para **refinar los híper-parámetros (hyperparameter tunning)**. Por último, el 10% final corresponde a su **testing dataset** usted **evaluará la performance** con este dataset.\n",
    "\n",
    "Este proceso conocido como cross-validation intenta evitar principalmente dos problemas: **underfitting y overfitting**. Siguiendo con la analogía, **underfitting** sería la situación en la que usted se entrena con pocos exámenes, estudiando y entendiendo poco, por lo que a la hora de dar el examen tendrá pésimos resultados. Por otro lado, **overfitting** sería la situación en la que usted se ha memorizado los exámenes con sus soluciones. Si tiene suerte y le toca un exámen muy parecido a los que ha visto tendrá una performance excelente, pero si apenas lo mueven de sus conocimientos tendrá una performance horrible.\n",
    "\n",
    "En la práctica, el **underfitting** suele producirse cuando:\n",
    "- Se entrena un modelo muy sencillo, que no es capaz de captar la complejidad subyacente de nuestros datos.\n",
    "- Se entrena datos que no cumplen con los supuestos del modelo.\n",
    "- Se entrena con muy pocos datos.\n",
    "\n",
    "En la práctica, el **overfitting** suele producirse cuando:\n",
    "- Se entrena un modelo muy complejo.\n",
    "- La proporción de training es sumamente mayor que la de validation y testing, memorizando los datos.\n",
    "- Se entrena con muy pocos datos.\n",
    "\n",
    "Lo que se busca es lo que se conoce como **\"just right\"**. Es decir, que el modelo verdaderamente aprenda, que sea robusto y esté preparado para enfrentarse a lo desconocido. En el futuro, usted aprenderá como se relacionan estos fenómenos con los conceptos de **sesgo y varianza** pero en este curso se brinda una mera intuición."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='289C4E'>7) Wine dataset<font> <a class='anchor' id='7'></a> [↑](#inicio)\n",
    "    \n",
    "Usted es un vitivinicultor con muchos años de experiencia. Sin embargo, para no quedar atrás con la competencia decide utilizar data science para además de basarse en su experiencia basarse en datos. A lo largo de los años a juntado información de distintas características de sus vinos y le ha asignado un nivel de calidad a cada uno. Desea entrenar un modelo lineal para predecir la calidad de sus vinos conocidas sus características.\n",
    "\n",
    "Para eso:\n",
    "1. Divida el dataset en:\n",
    "    - **X**, el dataset que contiene las columnas que utilizará para predecir la calidad del vino.\n",
    "    - **y**, la columna objetivo, es decir, la columna a predecir.\n",
    "2. Utilize la función [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) para obtener los datasets **X_train, X_test, y_train, y_test**. Para eso:\n",
    "    - Configure el parámetro **train_size** a 0.8\n",
    "    - Configure el parámetro **random_state** a 27 (para que su experimento sea reproducible).\n",
    "3. Imprima las dimensiones de los 4 datasets para corroborar que estén bien.\n",
    "4. Entrene el modelo lineal. \n",
    "5. Evalúe el modelo usando MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wine = pd.read_csv('./data/wine.csv', sep=';')\n",
    "display(wine.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='289C4E'>8) Hyperparameter tunning<font> <a class='anchor' id='8'></a> [↑](#inicio)\n",
    "    \n",
    "En el mundo de Machine Learning, es tomado como una regla general el hecho de tomar un split de 80% para training y 20% para testing. Esta regla surge del principio de Pareto. Sin embargo, se ha demostrado empíricamente que a medida que el volumen de datos crece esto deja de ser cierto y en **deep learning** llegan a tomarse splits de 99% y 1%. \n",
    "\n",
    "Al ser su volumen de datos es extremadamente bajo (~1600 registros) sería entendible regirse por el principio de Pareto. De todos modos, usted quiere sacar el mayor jugo a la performance del modelo y quiere evaluar distintos splits.\n",
    "\n",
    "Para eso:\n",
    "1. Repita mediante un loop el proceso anterior, guardando en una lista llamada `split` el tamaño del split de entrenamiento y en otra lista llamada `metric` el resultado de la métrica para ese split. Deberá probar desde un `training_size` de **30%** a un `training_size` de **95%** tomando incrementos de **5%** en cada iteración.\n",
    "2. Grafique estas dos variables para determinar visualmente el mejor split.\n",
    "3. Conteste:\n",
    "    - Cuál es el mejor split?\n",
    "    - Qué fenómeno ocurre para el menor split?\n",
    "    - Qué fenómeno ocurre para el mayor split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='289C4E'>9) Logistic regression<font> <a class='anchor' id='9'></a> [↑](#inicio)\n",
    "    \n",
    "La regresión logística es un modelo simple utilizado en problemas de clasificación binaria. Anteriormente, hemos visto que la regresión lineal se utilizaba para predecir una variable continua. En este caso, la regresión logística es utilizada para predecir una variable binaria, es decir, dos posibles resultados de una variable (0 o 1) a partir de un conjunto de variables, las cuales pueden ser tanto continuas como discretas. \n",
    "\n",
    "Mientras que la regresión lineal buscaba la línea de mejor ajuste minimizando $R^2$, la regresión logística busca la mejor función logística que maximiza la máxima verosimilitud (Maximum likelihood estimation). \n",
    "\n",
    "En el siguiente ejemplo, usted dispone de un dataset con registros históricos de estudiantes que han aplicado a distintas universidades. Este dataset contiene algunos datos como los puntajes de ciertos exámenes y la chance de ser admitido en una determinada universidad.\n",
    "\n",
    "Usted quiere saber si entrará o no a una universidad particular. Para eso usted considera que si la chance de admisión es superior a 80% usted definitivamente entrará a la universidad y si es menor no entrará.\n",
    "\n",
    "Para eso decide entrenar un modelo de regresión logística:\n",
    "1. Divida el dataset en:\n",
    "    - **X**, el dataset que contiene las columnas que utilizará para predecir si entrará o no.\n",
    "    - **y**, la columna objetivo, es decir, la columna a predecir.\n",
    "2. Convierta la columna objetivo de continua a binaria.\n",
    "3. Divida sus datasets en training y testing tomando un split de 80% y un `random_state` = 27 para reproducibilidad.\n",
    "4. Al ser un problema de clasificación no es posible evaluar la performance del modelo mediante MAE o RMSE. Evalúe la performance usando accuracy, precision, recall y F1.\n",
    "5. Grafique la [matriz de confusión](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) usando [sns.heatmap()](https://seaborn.pydata.org/generated/seaborn.heatmap.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='289C4E'>10) Decision tree classifiers<font> <a class='anchor' id='10'></a> [↑](#inicio)\n",
    "\n",
    "Los árboles de decisión son frecuentemente utilizados en problemas de clasificación binaria y discreta. Éstos toman decisiones hasta minimizar lo máximo posible métricas como la [impureza de Gini](https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity) o la [entropía de la información](https://en.wikipedia.org/wiki/Entropy_(information_theory)) en las hojas (nodos terminales). Los árboles de decisión tienen varios híper-parámetros, los más utilizados son:\n",
    "- `métrica:` qué métrica utilizar en los splits.\n",
    "- `profundidad:` cuántos nodos padres hay entre el nodo más hijo y el primer nodo.\n",
    "\n",
    "En el siguiente ejemplo, usted utilizará un dataset creado para este curso que contiene atributos de los personajes del clásico juego [\"Guess Who?\"](https://en.wikipedia.org/wiki/Guess_Who%3F). El árbol de decisión se entrenará con este dataset, de manera que aprenda a clasificar quién es quién.\n",
    "    \n",
    "**Nota:** en este ejemplo no dividiremos en train y test pues carece de sentido.\n",
    "\n",
    "Para esto:\n",
    "1. Cargue el CSV que contiene los personajes del juego y sus atributos.\n",
    "2. Separe el dataset de manera que:\n",
    "    - X sean las variables de entrenamiento.\n",
    "    - y sea la variable objetivo.\n",
    "3. Entrene el [árbol de decisión](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\n",
    "4. Grafique el árbol de decisión usando [plot_tree()](https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html). Establezca los parámetros `feature_names` y `class_names`. Se recomienda agregar figsize muy grande para visualizar bien la imágen.\n",
    "5. Utilize el árbol para predecir el registro `prediction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = [0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,1,0,0,0,0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
